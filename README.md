# ğŸ–¼ï¸ Image Captioning and Segmentation System

A complete web-based system for generating **image captions** and performing **semantic segmentation** using **pre-trained models** from PyTorch and Hugging Face Transformers. Built using **Streamlit**, it requires **no custom model training**.

---

## ğŸŒ Live Demo

ğŸ‘‰ [Try it Live on Streamlit](https://image-caption-bhaumik.streamlit.app/)

---

## ğŸš€ Features

- âœ¨ **Image Captioning**:
  - Uses **BLIP (Bootstrapped Language Image Pretraining)** model from Salesforce.
  - Generates descriptive captions from images.
  - Supports **conditional captioning** with user-defined prompts.

- ğŸ¯ **Image Segmentation**:
  - Uses **DeepLabV3 + ResNet101** pretrained on COCO.
  - Provides colored overlays of segmented regions.
  - Identifies and counts multiple object categories.

- ğŸ“· **Input Options**:
  - Upload image
  - Use sample images
  - Capture via camera (OpenCV or Streamlit webcam)

- ğŸ“Š **Evaluation Metrics**:
  - BLEU score for caption quality
  - IoU (Intersection over Union) for segmentation

---

## ğŸ›  Requirements

Install all dependencies using:

```bash
pip install torch torchvision transformers opencv-python pillow numpy matplotlib streamlit sentence-transformers
```
## ğŸ“ Directory Structure

```bash
image-captioning-and-segmentation/
â”‚
â”œâ”€â”€ Main.py                    # Main app file for Streamlit
â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ packages.txt               # System-level dependencies for Streamlit Cloud
â””â”€â”€ (Other helper files/images if needed)
```

## ğŸ’» Local Usage

Run the Streamlit app locally with:

```bash
streamlit run Main.py
```
## ğŸ“¦ Deployment on Streamlit Cloud

If deploying to Streamlit Cloud, ensure the following files are included:

### `requirements.txt`
```txt
torch
torchvision
transformers
opencv-python
numpy
Pillow
matplotlib
streamlit
requests
sentence-transformers
```

### `packages.txt`
```txt
libgl1-mesa-glx
```

## ğŸ§  Models Used

- ğŸ¤– `Salesforce/blip-image-captioning-base` (HuggingFace Transformers)  
- ğŸ§  `deeplabv3_resnet101` (Torchvision)

## ğŸ“· Sample Image Sources

All sample images are fetched from [Unsplash](https://unsplash.com).

## ğŸ“œ License

MIT License. Feel free to use, share, and modify this project.

## ğŸ‘¨â€ğŸ’» Author

Built with â¤ï¸ by **Bhaumik Senwal**

